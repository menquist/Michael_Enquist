{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machine Implementation with MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import the Required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Read the MNIST files \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set up the parameters for training \n",
    "\n",
    "\n",
    "n_visible      = 784\n",
    "n_hidden    = 500\n",
    "display_step = 1\n",
    "num_epochs = 200 \n",
    "batch_size = 256 \n",
    "lr         = tf.constant(0.001, tf.float32)\n",
    "\n",
    "## Define the tensorflow variables for weights and biases as well as placeholder for input\n",
    "x  = tf.placeholder(tf.float32, [None, n_visible], name=\"x\") \n",
    "W  = tf.Variable(tf.random_normal([n_visible, n_hidden], 0.01), name=\"W\") \n",
    "b_h = tf.Variable(tf.zeros([1, n_hidden],  tf.float32, name=\"b_h\")) \n",
    "b_v = tf.Variable(tf.zeros([1, n_visible],  tf.float32, name=\"b_v\")) \n",
    "\n",
    "## Converts the probability into discrete binary states i.e. 0 and 1 \n",
    "def sample(probs):\n",
    "    return tf.floor(probs + tf.random_uniform(tf.shape(probs), 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gibbs sampling step\n",
    "def gibbs_step(x_k):\n",
    "        h_k = sample(tf.sigmoid(tf.matmul(x_k, W) + b_h)) \n",
    "        x_k = sample(tf.sigmoid(tf.matmul(h_k, tf.transpose(W)) + b_v))\n",
    "        return x_k\n",
    "## Run multiple gives Sampling step starting from an initital point     \n",
    "def gibbs_sample(k,x_k):\n",
    "    for i in range(k):\n",
    "        x_out = gibbs_step(x_k) \n",
    "# Returns the gibbs sample after k iterations\n",
    "    return x_out\n",
    "\n",
    "# Constrastive Divergence algorithm\n",
    "# 1. Through Gibbs sampling locate a new visible state x_sample based on the current visible state x    \n",
    "# 2. Based on the new x sample a new h as h_sample    \n",
    "x_s = gibbs_sample(2,x) \n",
    "h_s = sample(tf.sigmoid(tf.matmul(x_s, W) + b_h)) \n",
    "\n",
    "# Sample hidden states based given visible states\n",
    "h = sample(tf.sigmoid(tf.matmul(x, W) + b_h)) \n",
    "# Sample visible states based given hidden states\n",
    "x_ = sample(tf.sigmoid(tf.matmul(h, tf.transpose(W)) + b_v))\n",
    "\n",
    "# The weight updated based on gradient descent \n",
    "size_batch = tf.cast(tf.shape(x)[0], tf.float32)\n",
    "W_add  = tf.multiply(lr/size_batch, tf.subtract(tf.matmul(tf.transpose(x), h), tf.matmul(tf.transpose(x_s), h_s)))\n",
    "bv_add = tf.multiply(lr/size_batch, tf.reduce_sum(tf.subtract(x, x_s), 0, True))\n",
    "bh_add = tf.multiply(lr/size_batch, tf.reduce_sum(tf.subtract(h, h_s), 0, True))\n",
    "updt = [W.assign_add(W_add), b_v.assign_add(bv_add), b_h.assign_add(bh_add)]\n",
    "\n",
    "# TensorFlow graph execution\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the variables of the Model\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    # Start the training \n",
    "    for epoch in range(num_epochs):\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            # Run the weight update \n",
    "            batch_xs = (batch_xs > 0)*1\n",
    "            _ = sess.run([updt], feed_dict={x:batch_xs})\n",
    "            \n",
    "        # Display the running step \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1))\n",
    "                  \n",
    "    print(\"RBM training Completed !\")\n",
    "    \n",
    "    \n",
    "    out = sess.run(h,feed_dict={x:(mnist.test.images[:20]> 0)*1})\n",
    "    label = mnist.test.labels[:20]\n",
    "    \n",
    "    plt.figure(1)\n",
    "    for k in range(20):\n",
    "        plt.subplot(4, 5, k+1)\n",
    "        image = (mnist.test.images[k]> 0)*1\n",
    "        image = np.reshape(image,(28,28))\n",
    "        plt.imshow(image,cmap='gray')\n",
    "       \n",
    "    plt.figure(2)\n",
    "    \n",
    "    for k in range(20):\n",
    "        plt.subplot(4, 5, k+1)\n",
    "        image = sess.run(x_,feed_dict={h:np.reshape(out[k],(-1,n_hidden))})\n",
    "        image = np.reshape(image,(28,28))\n",
    "        plt.imshow(image,cmap='gray')\n",
    "        print(np.argmax(label[k]))\n",
    "        \n",
    "    W_out = sess.run(W)\n",
    "    \n",
    "    \n",
    "    sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
