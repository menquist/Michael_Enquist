{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of a Generative Adversarial Network with Mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "iter: 2000 cost of discriminator 0.3757931 cost of generator 2.327367\n",
      "iter: 3000 cost of discriminator 0.59264153 cost of generator 2.268923\n",
      "iter: 4000 cost of discriminator 0.7067015 cost of generator 2.448505\n",
      "iter: 5000 cost of discriminator 0.6334806 cost of generator 2.0213757\n",
      "iter: 6000 cost of discriminator 0.46668434 cost of generator 2.53869\n",
      "iter: 7000 cost of discriminator 0.70404875 cost of generator 2.3153837\n",
      "iter: 8000 cost of discriminator 0.6116177 cost of generator 2.351711\n",
      "iter: 9000 cost of discriminator 0.6478527 cost of generator 2.4296758\n",
      "iter: 10000 cost of discriminator 0.6558285 cost of generator 1.9399145\n",
      "iter: 11000 cost of discriminator 0.66191715 cost of generator 2.3117843\n",
      "iter: 12000 cost of discriminator 0.6539108 cost of generator 2.1033006\n",
      "iter: 13000 cost of discriminator 0.68082494 cost of generator 1.9107574\n",
      "iter: 14000 cost of discriminator 0.7210272 cost of generator 1.7856528\n",
      "iter: 15000 cost of discriminator 0.6950151 cost of generator 1.7967556\n",
      "iter: 16000 cost of discriminator 0.7639748 cost of generator 1.6015053\n",
      "iter: 17000 cost of discriminator 0.81064725 cost of generator 1.7271817\n",
      "iter: 18000 cost of discriminator 0.6901691 cost of generator 1.718324\n",
      "iter: 19000 cost of discriminator 0.7195927 cost of generator 1.7979858\n",
      "iter: 20000 cost of discriminator 0.87193286 cost of generator 1.3994464\n",
      "iter: 21000 cost of discriminator 0.7857752 cost of generator 1.5393585\n",
      "iter: 22000 cost of discriminator 0.87608624 cost of generator 1.5071027\n",
      "iter: 23000 cost of discriminator 0.89946324 cost of generator 1.4797163\n",
      "iter: 24000 cost of discriminator 0.8278564 cost of generator 1.5145935\n",
      "iter: 25000 cost of discriminator 0.9268932 cost of generator 1.3692553\n",
      "iter: 26000 cost of discriminator 0.9815233 cost of generator 1.2512157\n",
      "iter: 27000 cost of discriminator 0.9768361 cost of generator 1.2991462\n",
      "iter: 28000 cost of discriminator 0.98719 cost of generator 1.2370448\n",
      "iter: 29000 cost of discriminator 1.0579436 cost of generator 1.207332\n",
      "iter: 30000 cost of discriminator 1.0075707 cost of generator 1.1008985\n",
      "iter: 31000 cost of discriminator 1.0662627 cost of generator 1.1406717\n",
      "iter: 32000 cost of discriminator 1.0372409 cost of generator 1.169423\n",
      "iter: 33000 cost of discriminator 0.99426764 cost of generator 1.1936426\n",
      "iter: 34000 cost of discriminator 1.0941973 cost of generator 1.1074421\n",
      "iter: 35000 cost of discriminator 0.98928964 cost of generator 1.1390535\n",
      "iter: 36000 cost of discriminator 1.1368805 cost of generator 1.161272\n",
      "iter: 37000 cost of discriminator 1.1881332 cost of generator 0.96725464\n",
      "iter: 38000 cost of discriminator 1.128436 cost of generator 1.0769527\n",
      "iter: 39000 cost of discriminator 1.0578356 cost of generator 1.134943\n",
      "iter: 40000 cost of discriminator 1.1232601 cost of generator 1.0167716\n",
      "iter: 41000 cost of discriminator 1.1457416 cost of generator 1.0576248\n",
      "iter: 42000 cost of discriminator 1.1208682 cost of generator 0.9953687\n",
      "iter: 43000 cost of discriminator 1.2035271 cost of generator 0.97363096\n",
      "iter: 44000 cost of discriminator 1.117711 cost of generator 1.0317628\n",
      "iter: 45000 cost of discriminator 1.0791969 cost of generator 1.0899521\n",
      "iter: 46000 cost of discriminator 1.100112 cost of generator 1.0339072\n",
      "iter: 47000 cost of discriminator 1.196494 cost of generator 0.98394036\n",
      "iter: 48000 cost of discriminator 1.1537701 cost of generator 1.006895\n",
      "iter: 49000 cost of discriminator 1.2037357 cost of generator 0.9593682\n",
      "iter: 50000 cost of discriminator 1.232707 cost of generator 0.8827381\n",
      "iter: 51000 cost of discriminator 1.1424445 cost of generator 1.0214453\n",
      "iter: 52000 cost of discriminator 1.2165234 cost of generator 0.9079754\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## The dimension of the Prior Noise Signal is 100 \n",
    "## The generator would have 150 and 300 hidden units successively before 784 outputs corresponding\n",
    "## to 28x28 image size\n",
    "\n",
    "h1_dim = 150\n",
    "h2_dim = 300\n",
    "dim = 100\n",
    "batch_size = 256\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# Define the generator - take noise and convert them to images\n",
    "#--------------------------------------------------------------\n",
    "def generator_(z_noise):\n",
    "    w1 = tf.Variable(tf.truncated_normal([dim,h1_dim], stddev=0.1), name=\"w1_g\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h1_dim]), name=\"b1_g\", dtype=tf.float32)\n",
    "    h1 = tf.nn.relu(tf.matmul(z_noise, w1) + b1)\n",
    "    w2 = tf.Variable(tf.truncated_normal([h1_dim,h2_dim], stddev=0.1), name=\"w2_g\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h2_dim]), name=\"b2_g\", dtype=tf.float32)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2_dim,28*28],stddev=0.1), name=\"w3_g\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([28*28]), name=\"b3_g\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "    out_gen = tf.nn.tanh(h3)\n",
    "    weights_g = [w1, b1, w2, b2, w3, b3]\n",
    "    return out_gen,weights_g\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Define the Discriminator - take both real images  and synthetic fake images \n",
    "# from Generator and classify the real and fake images properly\n",
    "#---------------------------------------------------------------------------\n",
    "def discriminator_(x,out_gen,keep_prob):\n",
    "    x_all = tf.concat([x,out_gen], 0)\n",
    "    w1 = tf.Variable(tf.truncated_normal([28*28, h2_dim], stddev=0.1), name=\"w1_d\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h2_dim]), name=\"b1_d\", dtype=tf.float32)\n",
    "    h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_all, w1) + b1), keep_prob)\n",
    "    w2 = tf.Variable(tf.truncated_normal([h2_dim, h1_dim], stddev=0.1), name=\"w2_d\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h1_dim]), name=\"b2_d\", dtype=tf.float32)\n",
    "    h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1,w2) + b2), keep_prob)\n",
    "    w3 = tf.Variable(tf.truncated_normal([h1_dim, 1], stddev=0.1), name=\"w3_d\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([1]), name=\"d_b3\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "    y_data = tf.nn.sigmoid(tf.slice(h3, [0, 0], [batch_size, -1], name=None))\n",
    "    y_fake = tf.nn.sigmoid(tf.slice(h3, [batch_size, 0], [-1, -1], name=None))\n",
    "    weights_d = [w1, b1, w2, b2, w3, b3]\n",
    "    return y_data,y_fake,weights_d\n",
    "\n",
    "\n",
    "\n",
    "# Read the MNIST datadet\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "## Place holder for the real images\n",
    "x = tf.placeholder(tf.float32, [batch_size, 28*28], name=\"x_data\")\n",
    "## Place holder for the noise\n",
    "z_noise = tf.placeholder(tf.float32, [batch_size,dim], name=\"z_prior\")\n",
    "## Dropout probability\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "# generate the output op for generator and also define the weights.\n",
    "out_gen,weights_g = generator_(z_noise)\n",
    "# Define the ops and weights for Discriminator\n",
    "y_data, y_fake,weights_d = discriminator_(x,out_gen,keep_prob)\n",
    "## Cost function for Discriminator\n",
    "discr_loss = -1*tf.reduce_mean(tf.log(y_data) + tf.log(1 - y_fake))\n",
    "## Cost function for Generator\n",
    "gen_loss = -1*tf.reduce_mean( tf.log(y_fake))\n",
    "optimizer = tf.train.AdamOptimizer(0.0001)\n",
    "d_trainer = optimizer.minimize(discr_loss,var_list=weights_d)\n",
    "g_trainer = optimizer.minimize(gen_loss,var_list=weights_g)\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "z_sample = np.random.uniform(-1, 1, size=(batch_size,dim)).astype(np.float32)\n",
    "\n",
    "for i in range(60000):\n",
    "    batch_x, _ = mnist.train.next_batch(batch_size)\n",
    "    x_value = 2*batch_x.astype(np.float32) - 1\n",
    "    z_value = np.random.uniform(-1, 1, size=(batch_size,dim)).astype(np.float32)\n",
    "    sess.run(d_trainer,feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "    sess.run(g_trainer,feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "    if (i % 1000 == 0) and(i > 1000):\n",
    "        c1,c2 = sess.run([discr_loss,gen_loss],feed_dict={x:x_value, z_noise:z_value,keep_prob:0.7})\n",
    "        print ('iter:',i,'cost of discriminator',c1, 'cost of generator',c2)\n",
    "out_val_img = sess.run(out_gen,feed_dict={z_noise:z_sample})     \n",
    "img = 0.5*(out_val_img[3,:] + 1)\n",
    "img = np.reshape(img,(28,28))\n",
    "plt.imshow(img*255)\n",
    "saver.save(sess, \"newgan_\",global_step=i)\n",
    "imgs = 0.5*(out_val_img + 1)\n",
    "for k in range(36):\n",
    "    plt.subplot(6,6,k+1)\n",
    "    image = np.reshape(imgs[k],(28,28))\n",
    "    plt.imshow(image,cmap='gray')\n",
    "   \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
